{
    "config": {
        "output": "results/MLP/churn/108",
        "dataset": "churn",
        "normalization": "quantile",
        "model": "MLP",
        "seed": 108,
        "early_stop": 16
    },
    "final": 0.856,
    "best": 0.865,
    "losses": "[0.5287793290615082, 0.45198154270648955, 0.4341035705804825, 0.4269878536462784, 0.4122374153137207, 0.3909269595146179, 0.3842343431711197, 0.3688536211848259, 0.36200119853019713, 0.3590684193372726, 0.3551782429218292, 0.34869808435440064, 0.3463223892450333, 0.34156178683042526, 0.3371570724248886, 0.3417750036716461, 0.33672693639993667, 0.33456737220287325, 0.3295108091831207, 0.3281853324174881, 0.33336213529109954, 0.32825931936502456, 0.32693793267011645, 0.32873210072517395, 0.3276319319009781, 0.32486048847436905, 0.32542082071304324, 0.3242924550175667, 0.322116102874279, 0.32050709664821625, 0.3192748123407364, 0.31538438409566877, 0.3133564665913582, 0.31649796426296234, 0.3145556676387787]",
    "val_score": "[0.79625, 0.79625, 0.79625, 0.79625, 0.829375, 0.840625, 0.840625, 0.85375, 0.855625, 0.860625, 0.860625, 0.860625, 0.859375, 0.861875, 0.86, 0.860625, 0.86125, 0.858125, 0.8625, 0.8575, 0.85375, 0.860625, 0.8625, 0.8625, 0.860625, 0.861875, 0.855625, 0.85, 0.85625, 0.855, 0.85875, 0.85875, 0.855625, 0.8525, 0.851875]",
    "test_score": "[0.7965, 0.7965, 0.7965, 0.7965, 0.823, 0.8385, 0.845, 0.842, 0.8545, 0.8535, 0.8545, 0.8595, 0.851, 0.8525, 0.8555, 0.8575, 0.859, 0.8545, 0.856, 0.8555, 0.8565, 0.859, 0.8585, 0.8615, 0.856, 0.8595, 0.853, 0.8485, 0.8565, 0.854, 0.86, 0.865, 0.862, 0.8605, 0.862]",
    "cfg": {
        "eval_score": 0.8675,
        "n_trial": 46,
        "dataset": "churn",
        "normalization": "quantile",
        "model": {
            "dropout": 0.28575658855839514,
            "d_embedding": 307,
            "d_layers": [
                141,
                325,
                325,
                325,
                325,
                325,
                356
            ]
        },
        "training": {
            "batch_size": 128,
            "eval_batch_size": 8192,
            "optimizer": "adamw",
            "lr": 0.0003674679741065295,
            "weight_decay": 0.00019286797939906382
        }
    }
}