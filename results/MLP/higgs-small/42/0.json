{
    "config": {
        "output": "results/MLP/higgs-small/42",
        "dataset": "higgs-small",
        "normalization": "quantile",
        "model": "MLP",
        "seed": 42,
        "early_stop": 16
    },
    "final": 0.717440081591025,
    "best": 0.7196328403875574,
    "losses": "[0.6691310211894957, 0.636267256446001, 0.621000443532215, 0.610623225933168, 0.6009810305223232, 0.5950294335683187, 0.5907351994902138, 0.5852664626710783, 0.5807383128298007, 0.5775000671061074, 0.5737582425761029, 0.5697523898225489, 0.5686098390478429, 0.566002624790843, 0.5637830626673814, 0.561275776808824, 0.5590276272316289, 0.5580598498747601, 0.5566149140761151, 0.5547561887803116, 0.5543638782772592, 0.5525729002022162, 0.5515666802724203, 0.5499114466876518, 0.5481114697650196, 0.5486095174541318, 0.5468101084716921, 0.5450994963568401, 0.5449555249718147, 0.5432573498749151, 0.5426319483819046, 0.5430619343509518, 0.5444826650910262, 0.5403512081479639, 0.5398211643947819, 0.5398379530363936, 0.5368925735233275, 0.5368468184781269, 0.5368149920207698, 0.5385519137712029, 0.5369317308674014, 0.535601858443361, 0.5341445927212878, 0.5349289091621957, 0.5350430738635179, 0.5343284955838832, 0.5336296689219591, 0.5320393171736865, 0.5332234683560162, 0.5313946260669367, 0.5312456982891735, 0.5305620000614384, 0.5306542692630272, 0.5297365317015144, 0.5294693776262485, 0.5290136286398259, 0.5303492858642485, 0.5280893912644891, 0.5282868842283884, 0.5281951032518372, 0.5279236351086841, 0.5272873140932098, 0.5266792684551177]",
    "val_score": "[0.6541305456399796, 0.6721060683324834, 0.6907190209077001, 0.7002167261601224, 0.7022565017848037, 0.7058261091279959, 0.7085670576236613, 0.7067822539520653, 0.7113717491075982, 0.7111805201427843, 0.713092809790923, 0.714622641509434, 0.7158975012748597, 0.7176823049464559, 0.7153875573686894, 0.7173635900050994, 0.7169173890872004, 0.7150050994390617, 0.7167899031106578, 0.7171086180520143, 0.7168536460989291, 0.720996940336563, 0.7204869964303927, 0.7188934217236104, 0.7195308516063234, 0.7193396226415094, 0.72035951045385, 0.7211881693013769, 0.7230367159612443, 0.7198495665476797, 0.7172361040285569, 0.72035951045385, 0.7211881693013769, 0.7213793982661907, 0.7237378888322284, 0.7232916879143294, 0.7241203467618562, 0.7237378888322284, 0.7246940336562978, 0.7236104028556859, 0.7232916879143294, 0.7254589495155533, 0.7237378888322284, 0.726478837327894, 0.7250764915859256, 0.7257139214686384, 0.7274349821519633, 0.7227180010198878, 0.7221443141254462, 0.7254589495155533, 0.7243753187149413, 0.7246302906680265, 0.7241203467618562, 0.725841407445181, 0.72431157572667, 0.724502804691484, 0.7249490056093829, 0.7246940336562978, 0.7255864354920959, 0.7260326364099949, 0.7243753187149413, 0.7246302906680265, 0.7259688934217237]",
    "test_score": "[0.6485466598674146, 0.6704232534421214, 0.6850076491585926, 0.6942886282508924, 0.6982151963284039, 0.6988271290158082, 0.6992860785313616, 0.7005099439061703, 0.7038245792962774, 0.7034166241713411, 0.7082610912799592, 0.7049974502804691, 0.7089240183579806, 0.7076491585925548, 0.7082100968893422, 0.7081591024987252, 0.7075471698113207, 0.7097399286078532, 0.7086690464048955, 0.7098419173890872, 0.7113207547169811, 0.7105048444671086, 0.7125956144824069, 0.7133095359510454, 0.7131055583885773, 0.7138704742478328, 0.7130035696073432, 0.7134115247322794, 0.714176440591535, 0.7133095359510454, 0.714278429372769, 0.7164201937786844, 0.7158082610912799, 0.7153493115757267, 0.7148903620601734, 0.7161652218255992, 0.7157062723100459, 0.7140744518103008, 0.715961244263131, 0.7180010198878123, 0.715859255481897, 0.7154003059663437, 0.7133095359510454, 0.7153493115757267, 0.7163182049974502, 0.717491075981642, 0.717440081591025, 0.7161652218255992, 0.7148393676695564, 0.7163182049974502, 0.7145843957164711, 0.7163182049974502, 0.7160122386537481, 0.7161142274349821, 0.7154513003569607, 0.7171341152473228, 0.7165221825599184, 0.7164201937786844, 0.7163691993880673, 0.7196328403875574, 0.717542070372259, 0.7181540030596635, 0.7187659357470678]",
    "cfg": {
        "normalization": "quantile",
        "model": {
            "d_layers": [
                231,
                121
            ],
            "dropout": 0.4896848511498748,
            "d_embedding": null
        },
        "training": {
            "batch_size": 512,
            "eval_batch_size": 8192,
            "lr": 0.0007537468376056318,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 0.0
        }
    }
}