{
    "config": {
        "output": "results/MLP/higgs-small/53",
        "dataset": "higgs-small",
        "normalization": "quantile",
        "model": "MLP",
        "seed": 53,
        "early_stop": 16
    },
    "final": 0.7176950535441101,
    "best": 0.7204997450280469,
    "losses": "[0.6689966999418367, 0.6375935436264286, 0.6215080347487597, 0.6098225809694305, 0.6022958973558937, 0.5957063339590057, 0.5892844524809985, 0.5843645125869813, 0.5803160870947489, 0.5761971677221903, 0.5719787788584949, 0.5700302933289753, 0.5669263286319205, 0.567336742470904, 0.5629497761648845, 0.5611923404825412, 0.5591247057527061, 0.5578910664814275, 0.5548797337020316, 0.5553499387531746, 0.5534034981960203, 0.5519462252050881, 0.5524088333292705, 0.5501722562603835, 0.5485702903290105, 0.5481008853369612, 0.5462234257682552, 0.545308862759815, 0.5445794274167317, 0.5431586639667915, 0.5431010933910928, 0.5413363784309325, 0.5429153885783219, 0.5405928923831722, 0.5400475433202294, 0.5391695695679363, 0.5387982813323416, 0.5379268556106381, 0.5380070752244654, 0.5374163709035734, 0.5364817174954143, 0.5341891021263309, 0.5345827716637434, 0.5352160378200251, 0.5344932367646598, 0.5310159766577124, 0.5306074105627169, 0.5326762301165883, 0.5314600947426587, 0.5323878153552853, 0.5306328329128948, 0.53062007921498, 0.5303842854209062, 0.5310239326663133, 0.529667439741817, 0.5303162828208955, 0.5276530501319141, 0.5287702800781746, 0.5278148319178481, 0.5285772618239488, 0.5277625671247157, 0.526379667888812, 0.5267073904595724, 0.5266122931871957]",
    "val_score": "[0.6501784803671596, 0.6735084140744518, 0.6881693013768485, 0.698814380418154, 0.7024477307496175, 0.708694543600204, 0.710670576236614, 0.7110530341662417, 0.7118179500254972, 0.714622641509434, 0.7140489546149924, 0.7164074451810301, 0.7164711881693013, 0.7165349311575727, 0.717044875063743, 0.7176185619581846, 0.7176185619581846, 0.7188934217236104, 0.7176823049464559, 0.717937276899541, 0.719020907700153, 0.7189571647118816, 0.7196583375828659, 0.7177460479347272, 0.7207419683834778, 0.719913309535951, 0.721443141254462, 0.720550739418664, 0.722526772055074, 0.7204869964303927, 0.7242478327383988, 0.7228454869964304, 0.7216981132075472, 0.7219530851606323, 0.7246302906680265, 0.723419173890872, 0.722526772055074, 0.7240566037735849, 0.7236741458439572, 0.7236741458439572, 0.7244390617032126, 0.7228454869964304, 0.7248852626211116, 0.7265425803161653, 0.723419173890872, 0.7267338092809791, 0.7242478327383988, 0.7276262111167772, 0.7252039775624681, 0.7238016318204997, 0.7249490056093829, 0.7257139214686384, 0.7255226925038246, 0.7236741458439572, 0.7259051504334523, 0.7239928607853137, 0.7252677205507394, 0.7232279449260581, 0.7263513513513513, 0.7243753187149413, 0.7250764915859256, 0.7259688934217237, 0.7246940336562978, 0.7269250382457929]",
    "test_score": "[0.6423253442121367, 0.6668026517083121, 0.6821009688934218, 0.6906680265170831, 0.6931667516573177, 0.6970933197348291, 0.6995920448750638, 0.7013258541560429, 0.7012238653748087, 0.7021927587965324, 0.703059663437022, 0.7048954614992351, 0.7050484446710862, 0.7081591024987252, 0.7081081081081081, 0.7073941866394696, 0.7079041305456399, 0.7087200407955125, 0.7087710351861295, 0.7086180520142784, 0.7096889342172361, 0.7108108108108108, 0.7109127995920449, 0.7122896481387048, 0.7132585415604283, 0.7148393676695564, 0.7135135135135136, 0.7153493115757267, 0.7137684854665987, 0.7148393676695564, 0.7159102498725141, 0.7156552779194288, 0.7145843957164711, 0.7144314125446201, 0.7159102498725141, 0.7183069862315146, 0.7157062723100459, 0.717542070372259, 0.7161142274349821, 0.7160122386537481, 0.7164711881693013, 0.7177460479347272, 0.7183069862315146, 0.7160122386537481, 0.7170831208567058, 0.7182559918408975, 0.7167261601223865, 0.7176950535441101, 0.7200407955124937, 0.7177970423253442, 0.7181540030596635, 0.7194798572157063, 0.7167771545130036, 0.7152473227944927, 0.7198368179500255, 0.7177460479347272, 0.7180010198878123, 0.7166241713411525, 0.718969913309536, 0.7178990311065783, 0.7204997450280469, 0.7186639469658338, 0.717389087200408, 0.7196838347781744]",
    "cfg": {
        "normalization": "quantile",
        "model": {
            "d_layers": [
                231,
                121
            ],
            "dropout": 0.4896848511498748,
            "d_embedding": null
        },
        "training": {
            "batch_size": 512,
            "eval_batch_size": 8192,
            "lr": 0.0007537468376056318,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 0.0
        }
    }
}