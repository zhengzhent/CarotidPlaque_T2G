{
    "config": {
        "output": "results/FTTransformer/churn/163",
        "dataset": "churn",
        "normalization": "quantile",
        "model": "FTTransformer",
        "seed": 163,
        "early_stop": 16
    },
    "final": 0.8635,
    "best": 0.865,
    "losses": "[0.4247971552610397, 0.37312556207180025, 0.36706594526767733, 0.3614535140991211, 0.3520565378665924, 0.3548064026236534, 0.3524330115318298, 0.3495094287395477, 0.34345248878002166, 0.3408338525891304, 0.34456131398677825, 0.34228829383850096, 0.3364973071217537, 0.3359781503677368, 0.3347443675994873, 0.33262880116701127, 0.327519029378891, 0.3334162837266922, 0.33306814193725587, 0.33319531232118604, 0.33502192318439483, 0.33165361791849135, 0.32637740403413773, 0.32531058877706526, 0.3278263312578201, 0.3297932690382004, 0.32379153728485105, 0.3219342949986458, 0.3222402572631836]",
    "val_score": "[0.855625, 0.86125, 0.865625, 0.85125, 0.858125, 0.8675, 0.858125, 0.86875, 0.861875, 0.866875, 0.86625, 0.864375, 0.8725, 0.86875, 0.86375, 0.86375, 0.866875, 0.86125, 0.86375, 0.859375, 0.86, 0.8625, 0.86875, 0.86125, 0.8675, 0.863125, 0.86375, 0.87, 0.863125]",
    "test_score": "[0.8355, 0.8505, 0.8515, 0.8475, 0.851, 0.8505, 0.854, 0.855, 0.855, 0.86, 0.858, 0.8545, 0.8635, 0.8625, 0.857, 0.8595, 0.8635, 0.861, 0.8585, 0.86, 0.8555, 0.8605, 0.863, 0.8565, 0.865, 0.8605, 0.859, 0.863, 0.864]",
    "cfg": {
        "eval_score": 0.875,
        "n_trial": 14,
        "dataset": "churn",
        "normalization": "quantile",
        "model": {
            "activation": "reglu",
            "initialization": "kaiming",
            "n_heads": 8,
            "prenormalization": true,
            "attention_dropout": 0.38851887270951657,
            "d_ffn_factor": 2.051137191894386,
            "d_token": 248,
            "ffn_dropout": 0.2228527401603561,
            "n_layers": 3,
            "residual_dropout": 0.3071445891962632,
            "kv_compression": null,
            "kv_compression_sharing": null,
            "token_bias": true
        },
        "training": {
            "batch_size": 128,
            "eval_batch_size": 8192,
            "optimizer": "adamw",
            "lr": 0.0003249906976306008,
            "weight_decay": 0.00011223536015541326
        }
    }
}