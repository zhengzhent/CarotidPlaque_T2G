{
    "config": {
        "output": "results/FTTransformer/churn/119",
        "dataset": "churn",
        "normalization": "quantile",
        "model": "FTTransformer",
        "seed": 119,
        "early_stop": 16
    },
    "final": 0.8605,
    "best": 0.8655,
    "losses": "[0.4309700095653534, 0.3746165227890015, 0.3648542857170105, 0.36050967395305633, 0.35582562804222106, 0.3524715441465378, 0.3482228630781174, 0.346660458445549, 0.34614956796169283, 0.34457073360681534, 0.3416616004705429, 0.3432831406593323, 0.3387881374359131, 0.3386582571268082, 0.33776194125413894, 0.33402755320072175, 0.336187798678875, 0.33410594522953035, 0.3322890841960907, 0.3324916398525238, 0.3314256033301353, 0.33329300582408905, 0.32833321392536163, 0.32998321563005445, 0.33236504018306734, 0.32739335000514985, 0.3232759267091751]",
    "val_score": "[0.861875, 0.86125, 0.86375, 0.861875, 0.860625, 0.86875, 0.869375, 0.866875, 0.866875, 0.8575, 0.8725, 0.864375, 0.865625, 0.8675, 0.86125, 0.868125, 0.866875, 0.8675, 0.86125, 0.865625, 0.869375, 0.865, 0.87, 0.865, 0.8625, 0.860625, 0.860625]",
    "test_score": "[0.843, 0.8535, 0.854, 0.851, 0.8485, 0.8515, 0.856, 0.8555, 0.8505, 0.8515, 0.8605, 0.8555, 0.858, 0.8625, 0.857, 0.8585, 0.8595, 0.8565, 0.859, 0.862, 0.86, 0.863, 0.8605, 0.8655, 0.863, 0.8605, 0.8615]",
    "cfg": {
        "eval_score": 0.875,
        "n_trial": 14,
        "dataset": "churn",
        "normalization": "quantile",
        "model": {
            "activation": "reglu",
            "initialization": "kaiming",
            "n_heads": 8,
            "prenormalization": true,
            "attention_dropout": 0.38851887270951657,
            "d_ffn_factor": 2.051137191894386,
            "d_token": 248,
            "ffn_dropout": 0.2228527401603561,
            "n_layers": 3,
            "residual_dropout": 0.3071445891962632,
            "kv_compression": null,
            "kv_compression_sharing": null,
            "token_bias": true
        },
        "training": {
            "batch_size": 128,
            "eval_batch_size": 8192,
            "optimizer": "adamw",
            "lr": 0.0003249906976306008,
            "weight_decay": 0.00011223536015541326
        }
    }
}