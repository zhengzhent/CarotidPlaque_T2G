{
    "config": {
        "output": "results/FTTransformer/churn/152",
        "dataset": "churn",
        "normalization": "quantile",
        "model": "FTTransformer",
        "seed": 152,
        "early_stop": 16
    },
    "final": 0.8575,
    "best": 0.859,
    "losses": "[0.4374996203184128, 0.3721481972932816, 0.3675767695903778, 0.36030276119709015, 0.35071342408657075, 0.3499162966012955, 0.3475334966182709, 0.3464691960811615, 0.3409476202726364, 0.3435998260974884, 0.33986202657222747, 0.3407663941383362, 0.3377983623743057, 0.33580698728561403, 0.33361399948596954, 0.33510452568531035, 0.3326215094327927, 0.33477951407432555, 0.33130208164453506, 0.33154535949230196, 0.3283589202165604, 0.3311569803953171, 0.3328274470567703]",
    "val_score": "[0.864375, 0.85625, 0.8475, 0.86375, 0.86125, 0.86, 0.86625, 0.865625, 0.86375, 0.863125, 0.858125, 0.864375, 0.86375, 0.863125, 0.86125, 0.864375, 0.861875, 0.863125, 0.8625, 0.86625, 0.86625, 0.860625, 0.865]",
    "test_score": "[0.839, 0.8475, 0.843, 0.85, 0.8525, 0.853, 0.8575, 0.859, 0.855, 0.8555, 0.854, 0.854, 0.856, 0.857, 0.857, 0.8545, 0.8565, 0.856, 0.858, 0.857, 0.8585, 0.858, 0.859]",
    "cfg": {
        "eval_score": 0.875,
        "n_trial": 14,
        "dataset": "churn",
        "normalization": "quantile",
        "model": {
            "activation": "reglu",
            "initialization": "kaiming",
            "n_heads": 8,
            "prenormalization": true,
            "attention_dropout": 0.38851887270951657,
            "d_ffn_factor": 2.051137191894386,
            "d_token": 248,
            "ffn_dropout": 0.2228527401603561,
            "n_layers": 3,
            "residual_dropout": 0.3071445891962632,
            "kv_compression": null,
            "kv_compression_sharing": null,
            "token_bias": true
        },
        "training": {
            "batch_size": 128,
            "eval_batch_size": 8192,
            "optimizer": "adamw",
            "lr": 0.0003249906976306008,
            "weight_decay": 0.00011223536015541326
        }
    }
}