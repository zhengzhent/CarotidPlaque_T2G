{
    "config": {
        "output": "results/TabNet/churn/75",
        "dataset": "churn",
        "normalization": "quantile",
        "model": "TabNet",
        "seed": 75,
        "early_stop": 16
    },
    "final": 0.8525,
    "best": 0.8605,
    "losses": "[0.4584159404039383, 0.3609208250045776, 0.35126797735691073, 0.34657672941684725, 0.34500795006752016, 0.3413358849287033, 0.34100845336914065, 0.3376177626848221, 0.33666029691696164, 0.3350983771681786, 0.33434040665626524, 0.3313536775112152, 0.32988694697618487, 0.3280724075436592, 0.32860879123210907, 0.32583530992269516, 0.3261938926577568, 0.3256068551540375, 0.32368970900774, 0.3226316300034523, 0.3211742535233498, 0.3200552481412888, 0.32018315434455874, 0.3186656180024147, 0.31635564267635347, 0.3164204221963882, 0.3143669930100441, 0.3142817804217339, 0.313465319275856, 0.31436201333999636, 0.3123422303795815, 0.3106169986724854, 0.3111543107032776, 0.30970577150583267, 0.31004947155714035, 0.30854817628860476, 0.30876750737428665, 0.30630826532840727]",
    "val_score": "[0.79625, 0.806875, 0.85625, 0.855, 0.856875, 0.85875, 0.858125, 0.86125, 0.86125, 0.865625, 0.8625, 0.86125, 0.86125, 0.8625, 0.865625, 0.8625, 0.86125, 0.868125, 0.86625, 0.86625, 0.8675, 0.869375, 0.866875, 0.864375, 0.865, 0.86375, 0.865625, 0.865, 0.865625, 0.863125, 0.86, 0.86125, 0.863125, 0.86125, 0.86, 0.86, 0.860625, 0.8625]",
    "test_score": "[0.7965, 0.8075, 0.8525, 0.855, 0.854, 0.858, 0.859, 0.8605, 0.8605, 0.8595, 0.8585, 0.858, 0.8575, 0.8505, 0.854, 0.854, 0.854, 0.855, 0.855, 0.8555, 0.8545, 0.8525, 0.8525, 0.8525, 0.8545, 0.853, 0.853, 0.855, 0.857, 0.8535, 0.856, 0.8515, 0.8535, 0.8515, 0.851, 0.8525, 0.8535, 0.8505]",
    "cfg": {
        "model": {
            "batch_momentum": 0.95,
            "d_embedding": 128,
            "feature_dim": 64,
            "num_decision_steps": 3,
            "relaxation_factor": 1.333,
            "virtual_batch_size": 128,
            "output_dim": 64
        },
        "training": {
            "display_steps": 100,
            "epochs": 50000,
            "grad_thresh": 2000.0,
            "patience": 16,
            "schedule": {
                "decay_rate": 0.5,
                "decay_steps": 500,
                "learning_rate": 0.005
            },
            "sparsity_loss_weight": 0.001
        }
    }
}