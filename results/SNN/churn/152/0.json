{
    "config": {
        "output": "results/SNN/churn/152",
        "dataset": "churn",
        "normalization": "quantile",
        "model": "SNN",
        "seed": 152,
        "early_stop": 16
    },
    "final": 0.8595,
    "best": 0.862,
    "losses": "[0.5017782860994339, 0.4439642310142517, 0.4386992597579956, 0.43314055979251864, 0.41427743196487427, 0.3962642699480057, 0.3784682285785675, 0.38294835209846495, 0.3750221714377403, 0.37999203920364377, 0.3707361286878586, 0.3732360738515854, 0.36551944315433504, 0.3705943787097931, 0.36261617779731753, 0.3624910247325897, 0.3550755488872528, 0.35338492929935456, 0.35544838666915896, 0.3591839808225632, 0.3499806046485901, 0.3513186800479889, 0.34642078816890715, 0.3469529831409454, 0.3455167818069458, 0.35119908452034, 0.3476878920197487, 0.34643817752599715, 0.34820880949497224, 0.3479373547434807, 0.3437341967225075, 0.3429612198472023, 0.344935317337513, 0.34269443452358245, 0.3429128542542458, 0.34258300393819807, 0.33870297789573667, 0.3387021613121033, 0.33871676087379454, 0.34589430809020993, 0.33938798546791077, 0.3393165531754494, 0.3393178251385689, 0.3408746984601021]",
    "val_score": "[0.809375, 0.810625, 0.791875, 0.828125, 0.84125, 0.8, 0.84375, 0.833125, 0.793125, 0.85125, 0.853125, 0.85, 0.836875, 0.858125, 0.861875, 0.865, 0.85625, 0.85875, 0.841875, 0.863125, 0.85875, 0.865, 0.861875, 0.834375, 0.859375, 0.863125, 0.863125, 0.8675, 0.863125, 0.863125, 0.8525, 0.855, 0.860625, 0.853125, 0.86375, 0.864375, 0.858125, 0.860625, 0.8625, 0.86375, 0.860625, 0.858125, 0.859375, 0.85375]",
    "test_score": "[0.815, 0.8185, 0.784, 0.8335, 0.8355, 0.7895, 0.844, 0.8065, 0.7905, 0.8405, 0.8505, 0.8455, 0.8235, 0.851, 0.8555, 0.851, 0.8415, 0.852, 0.8335, 0.8555, 0.849, 0.8535, 0.8595, 0.8215, 0.855, 0.8595, 0.8535, 0.8595, 0.8565, 0.862, 0.842, 0.852, 0.8595, 0.8495, 0.8605, 0.8555, 0.8515, 0.855, 0.852, 0.854, 0.8505, 0.8525, 0.857, 0.848]",
    "cfg": {
        "eval_score": 0.871875,
        "n_trial": 27,
        "dataset": "churn",
        "normalization": "quantile",
        "model": {
            "dropout": 0.05652666214468672,
            "d_embedding": 386,
            "d_layers": [
                259,
                257,
                257,
                257,
                257,
                257,
                257,
                257,
                27
            ]
        },
        "training": {
            "batch_size": 128,
            "eval_batch_size": 8192,
            "optimizer": "adamw",
            "lr": 0.0013091134995944927,
            "weight_decay": 0.00017581546476641235
        }
    }
}