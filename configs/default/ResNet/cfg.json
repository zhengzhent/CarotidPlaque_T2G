{
    "model": {
        "activation": "relu",
        "d": 300,
        "d_embedding": 256,
        "d_hidden_factor": 2.0,
        "hidden_dropout": 0.5,
        "n_layers": 8,
        "normalization": "batchnorm",
        "residual_dropout": 0.0
    },
    "training": {
        "lr": 0.0001,
        "optimizer": "adamw",
        "patience": 16,
        "weight_decay": 1e-05
    }
}