{
    "dataset": "covtype",
    "normalization": "quantile",
    "model": {
        "activation": "relu",
        "attention_dropout": 0.003750469947937893,
        "d_token": 32,
        "initialization": "kaiming",
        "n_heads": 2,
        "n_layers": 5,
        "prenormalization": false,
        "residual_dropout": 0.0
    },
    "training": {
        "batch_size": 1024,
        "eval_batch_size": 8192,
        "lr": 0.0002466693609846615,
        "optimizer": "adamw",
        "patience": 16,
        "weight_decay": 0.0002565022252121103
    }
}