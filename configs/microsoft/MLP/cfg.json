{
    "normalization": "quantile",
    "model": {
        "d_layers": [
            916,
            247
        ],
        "dropout": 0.4151013678232672
    },
    "training": {
        "batch_size": 1024,
        "eval_batch_size": 8192,
        "lr": 6.150734353753627e-05,
        "optimizer": "adamw",
        "patience": 16,
        "weight_decay": 1.494554370167576e-05
    }
}